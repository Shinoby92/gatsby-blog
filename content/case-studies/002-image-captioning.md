---
title: Image Captioning
excerpt: This is a web app I built to show how to perform image captioning using an encoder decoder with an attention mechansim. The attention mechansim highlights where the network looks at when generating each token.

iframe: //www.youtube.com/embed/RlNjzz358Jc/?modestbranding=1&showinfo=0&autohide=1&rel=0
demo: //www.youtube.com/embed/RlNjzz358Jc/?modestbranding=1&showinfo=0&autohide=1&rel=0

info:
  idea: The idea of this project is to show how neural networks generate text from images and understand the generation process
  tech: [PyTorch, Javascript, HTML, CSS]
  links:
    - [
        Paper,
        https://arxiv.org/pdf/1502.03044.pdf
      ]
---

## How it works

This is a web demo that allows to perform image captioning with visual attention mechanism to highlight the areas of the image where the model look when generating a token.

The model implementation is in PyTorch and based on this [paper](https://arxiv.org/pdf/1502.03044.pdf) called: "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"

## Code 

Coming soon. 