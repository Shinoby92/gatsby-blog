---
title: Image Captioning
excerpt: How to translate an image to text with the ability to interpret what the machine learning algorithm sees? This is possible using neural networks and specifically encoder-decoders with attention mechanisms.

iframe: //www.youtube.com/embed/RlNjzz358Jc/?modestbranding=1&showinfo=0&autohide=1&rel=0
demo: //www.youtube.com/watch?v=RlNjzz358Jc

info:
  idea: The idea of this project is to show how neural networks generate text from images and understand the generation process
  tech: [PyTorch, Javascript, HTML, CSS]
  links:
    - [
        Paper,
        https://arxiv.org/pdf/1502.03044.pdf
      ]
---

## How it works

This is a web demo that allows to perform image captioning with visual attention mechanism to highlight the areas of the image where the model look when generating a token.

The model implementation is in PyTorch and based on this [paper](https://arxiv.org/pdf/1502.03044.pdf) called: "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"

## Code 
 
Coming soon. 